{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MHNC_TH9_18110181.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMY7y1d91gSJIjVspMiRo71"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"SdhDdkLuLcml","executionInfo":{"status":"ok","timestamp":1642512084872,"user_tz":-420,"elapsed":1202,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}}},"source":["import numpy as np\n","import gym\n","import time\n","from IPython.display import clear_output\n","env = gym.make(\"Taxi-v3\") #Gọi môi trường ra"],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["env.env.s=env.encode(1,1,2,0)\n","env.render()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2-HkgD7_R4p","executionInfo":{"status":"ok","timestamp":1642512084874,"user_tz":-420,"elapsed":15,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"ef22c351-9b02-4832-cabd-c93fe57f794e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| :\u001b[43m \u001b[0m| : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Naive Learning"],"metadata":{"id":"7s6lA6Z0UU8g"}},{"cell_type":"code","source":["state_size = env.observation_space.n\n","action_size = env.action_space.n\n","\n","q_table = np.zeros((state_size, action_size))\n","\n","FILE_SAVE_Naive = \"q_table_naive.npy\"\n","total_episodes = 500      # Total episodes\n","total_test_episodes = 10     # Total test episodes\n","max_steps = 99                # Max steps per episode\n","           # Exponential decay rate for exploration prob"],"metadata":{"id":"K50XIrHO_lCI","executionInfo":{"status":"ok","timestamp":1642512117570,"user_tz":-420,"elapsed":383,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import time\n","for episode in range(total_episodes):\n","    state = env.reset()   # reset lại môi trường\n","    done = False          # đã hoàn thành trả khách hay chưa\n","    for step in range(max_steps):\n","        clear_output(wait=True)\n","        print(\"episode: \",episode)\n","        if  np.max(q_table[state]) ==0:         # nếu trong state q_value đều bằng 0 thì chọn đại 1 action\n","            action=np.random.randint(0,action_size)\n","        else:\n","            action = np.argmax(q_table[state])  # chọn action có q_value lớn nhất\n","\n","        new_state, reward, done, _ = env.step(action)   # thực hiện hành động để nhận reward và state, action mới\n","\n","        q_table[state,action] += reward # cập nhật q_table\n","        state = new_state\n","        if done:       # nếu taxi có hành vi trả khách thì kết thúc episode\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_o-qMStm_s13","executionInfo":{"status":"ok","timestamp":1642512465791,"user_tz":-420,"elapsed":345721,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"88ba6f0e-cb86-4d7a-9d5d-828b3233a8e7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["episode:  499\n"]}]},{"cell_type":"code","source":["# lưu lại q_table\n","np.save(FILE_SAVE_Naive,q_table)"],"metadata":{"id":"dvgOsIg2_vBV","executionInfo":{"status":"ok","timestamp":1642512987904,"user_tz":-420,"elapsed":365,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# từ q_table bắt đầu chơi thử\n","q_table=np.load(\"q_table_naive.npy\")\n","rewards = []\n","\n","for episode in range(total_test_episodes):\n","    state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards = 0\n","    \n","\n","    for step in range(max_steps):\n","        print(\"****************************************************\")\n","        print(\"EPISODE \", episode)\n","        action = np.argmax(q_table[state,:])\n","        \n","        new_state, reward, done, info = env.step(action)\n","        env.render() # hiển thị trò chơi\n","        total_rewards += reward\n","        print(total_rewards)\n","        time.sleep(0.5)\n","        clear_output(wait=True)\n","        \n","        if done:\n","            rewards.append(total_rewards)\n","            #print (\"Score\", total_rewards)\n","            break\n","        state = new_state\n","env.close()\n","print (\"Score over time: \" +  str(sum(rewards)/total_test_episodes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"mRphKiXQRD6y","executionInfo":{"status":"error","timestamp":1642512999795,"user_tz":-420,"elapsed":10102,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"f3cab612-c413-4c98-c28d-d2c8a1582619"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["****************************************************\n","EPISODE  0\n","+---------+\n","|R: | : :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | :\u001b[43m \u001b[0m|\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (East)\n","-20\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-04ec51c28685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtotal_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["Q-Learning"],"metadata":{"id":"Yfr-J9zSUQFL"}},{"cell_type":"code","source":["env = gym.make(\"Taxi-v3\")\n","state_size = env.observation_space.n\n","action_size = env.action_space.n\n","\n","q_table = np.zeros((state_size, action_size))\n","\n","FILE_SAVE_Qlearning = \"q_table_qlearning.npy\"\n","total_episodes = 5000         # Total episodes\n","total_test_episodes = 10    # Total test episodes\n","max_steps = 99                # Max steps per episode\n","\n","learning_rate = 0.7           # Learning rate\n","discount_rate = 0.95         # Discounting rate\n","\n","# Exploration parameters\n","epsilon = 1.0                 # Exploration rate\n","max_epsilon = 1.0             # Exploration probability at start\n","min_epsilon = 0.01            # Minimum exploration probability \n","decay_rate = 0.01             # Exponential decay rate for exploration prob"],"metadata":{"id":"DDXAMCoIRHLX","executionInfo":{"status":"ok","timestamp":1642513004203,"user_tz":-420,"elapsed":338,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["q_table"],"metadata":{"id":"G0H_g5RWROHJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642513004556,"user_tz":-420,"elapsed":6,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"7ad02cf6-1c38-49f0-bd9e-232e994421f8"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import time\n","for episode in range(total_episodes):\n","    state = env.reset()\n","    done = False\n","    clear_output(wait=True)\n","    print(\"episode: \",episode)\n","    for step in range(max_steps):\n","        #clear_output(wait=True)\n","        \n","        epsilon = min(min_epsilon, epsilon*decay_rate)\n","        # kiểm tra xem agent dùng exploi hay explor\n","        if np.random.rand() < epsilon:\n","            # exploration\n","            action = np.random.randint(0, action_size)\n","        else:\n","            # exploitation\n","            if np.max(q_table[state])==0:\n","                action=np.random.randint(0,action_size)\n","            else:\n","                action = np.argmax(q_table[state])\n","            \n","        # nhận reward và state tiếp theo\n","        new_state, reward, done, _ = env.step(action)\n","\n","        # cập nhật q_table theo Bellman equation\n","        update = reward + discount_rate*q_table[new_state].max() - q_table[state,action]\n","        q_table[state,action] = q_table[state,action] + learning_rate*update\n","        state = new_state\n","        if done:\n","            break"],"metadata":{"id":"QiLAe9e7ROdN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642513040587,"user_tz":-420,"elapsed":34613,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"cbabb47b-8766-4325-e51b-e134fc5c4ed1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["episode:  4999\n"]}]},{"cell_type":"code","source":["# lưu lại q_table\n","np.save(FILE_SAVE_Qlearning,q_table)"],"metadata":{"id":"hfk-K8RXRQ3k","executionInfo":{"status":"ok","timestamp":1642513040587,"user_tz":-420,"elapsed":21,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# từ q_table bắt đầu chơi thử\n","#q_table=np.load(\"q_table_qlearning.npy\")\n","rewards = []\n","\n","for episode in range(total_test_episodes):\n","    state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards = 0\n","    \n","\n","    for step in range(max_steps):\n","        print(\"****************************************************\")\n","        print(\"EPISODE \", episode)\n","        \n","        action = np.argmax(q_table[state,:])\n","        new_state, reward, done, info = env.step(action)\n","        env.render() # hiển thị trò chơi\n","        total_rewards += reward\n","        print(total_rewards)\n","        time.sleep(0.5)\n","        clear_output(wait=True)\n","        \n","        if done:\n","            rewards.append(total_rewards)\n","            #print (\"Score\", total_rewards)\n","            break\n","        state = new_state\n","        \n","env.close()\n","print (\"Score over time: \" +  str(sum(rewards)/total_test_episodes))"],"metadata":{"id":"smqekhKxRT2D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642513091608,"user_tz":-420,"elapsed":51041,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"ea24a9e4-92e2-41d4-ef48-911266819f1e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Score over time: 8.2\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"1qhHlsQoRVcd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Giải thích vì sao khi dùng Naive-Learning thì xe taxi chỉ đứng yên một chỗ?\n","##### Naive-learning luôn chọn hành động có lợi nhất dựa trên những gì quan sát được. Nếu giá trị bằng 0 cho tất cả những hành động thì sẽ chọn một hành động ngẫu nhiên. Sau mỗi bước đi nếu như không đón khách hay trả khách được thì taxi sẽ bị -1 reward nên taxi sẽ chọn hành có lợi nhất là đứng yên một chỗ.\n","2. Giải thích vì sao khi dùng Q-Leaning thì xe taxi có thể đón và trả khách được?\n","##### Q-learning đầu tiên sẽ chọn hành động nhất dựa trên Q-table. Nhưng đôi khi thuật toán sẽ gamble và chọn một hành động ngẫu nhiên. Đó là lý do vì sao taxi có thể di chuyển đến cái điểm đón và trả khách.\n","3. Tìm hiểu một game khác trên OpenAI và thiết lập cho agent chơi được"],"metadata":{"id":"bBM_HmjZPH5q"}},{"cell_type":"markdown","source":["## Game Frozen-Lake\n","#### Ta sẽ khiển một nhân vật đi trên bề mặt băng với\n","#### S: điểm bắt đầu, an toàn\n","#### F: bề mặt băng, an toàn\n","#### H: lỗ, rơi xuống là thua\n","#### G: đích đến chến thắng\n","#### Trò chơi kết thúc khi bạn vền đích hoặc rơi cuống lỗ. Nếu về đích sẽ nhận được 1 reward, người lại là 0 reward\n"],"metadata":{"id":"-fghpBovbUHE"}},{"cell_type":"code","source":["env = gym.make(\"FrozenLake-v0\") #Gọi môi trường ra\n","#env = gym.make(\"Blackjack-v0\")\n","env.render()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqdGsP8wUdbI","executionInfo":{"status":"ok","timestamp":1639794686038,"user_tz":-420,"elapsed":6,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"05bdda67-88b4-4353-e922-ae556b1a1331"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n"]}]},{"cell_type":"code","source":["env = gym.make(\"FrozenLake-v0\")\n","state_size = env.observation_space.n\n","action_size = env.action_space.n\n","\n","q_table = np.zeros((state_size, action_size))\n","\n","FILE_SAVE_Qlearning = \"q_table_qlearning.npy\"\n","total_episodes = 50000         # Total episodes\n","total_test_episodes = 100    # Total test episodes\n","max_steps = 99                # Max steps per episode\n","\n","learning_rate = 0.7           # Learning rate\n","discount_rate = 0.95         # Discounting rate\n","\n","# Exploration parameters\n","epsilon = 1.0                 # Exploration rate\n","max_epsilon = 1.0             # Exploration probability at start\n","min_epsilon = 0.01            # Minimum exploration probability \n","decay_rate = 0.01             # Exponential decay rate for exploration prob"],"metadata":{"id":"7xLsYFI7UeRH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","for episode in range(total_episodes):\n","    state = env.reset()\n","    done = False\n","    clear_output(wait=True)\n","    print(\"episode: \",episode)\n","    for step in range(max_steps):\n","        #clear_output(wait=True)\n","        \n","        epsilon = min(min_epsilon, epsilon*decay_rate)\n","        # kiểm tra xem agent dùng exploi hay explor\n","        if np.random.rand() < epsilon:\n","            # exploration\n","            action = np.random.randint(0, action_size)\n","        else:\n","            # exploitation\n","            if np.max(q_table[state])==0:\n","                action=np.random.randint(0,action_size)\n","            else:\n","                action = np.argmax(q_table[state])\n","            \n","        # nhận reward và state tiếp theo\n","        new_state, reward, done, _ = env.step(action)\n","\n","        # cập nhật q_table theo Bellman equation\n","        update = reward + discount_rate*q_table[new_state].max() - q_table[state,action]\n","        q_table[state,action] = q_table[state,action] + learning_rate*update\n","        state = new_state\n","        if done:\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5b1wkrvUehn","executionInfo":{"status":"ok","timestamp":1639795151367,"user_tz":-420,"elapsed":419066,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"047f6bd2-0284-4986-86f6-aed40532aa20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["episode:  49999\n"]}]},{"cell_type":"code","source":["# từ q_table bắt đầu chơi thử\n","#q_table=np.load(\"q_table_qlearning.npy\")\n","rewards = []\n","\n","for episode in range(total_test_episodes):\n","    state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards = 0\n","    \n","\n","    for step in range(max_steps):\n","        print(\"****************************************************\")\n","        print(\"EPISODE \", episode)\n","        \n","        action = np.argmax(q_table[state,:])\n","        new_state, reward, done, info = env.step(action)\n","        env.render() # hiển thị trò chơi\n","        total_rewards += reward\n","        print(total_rewards)\n","        time.sleep(0.5)\n","        clear_output(wait=True)\n","        \n","        if done:\n","            rewards.append(total_rewards)\n","            #print (\"Score\", total_rewards)\n","            break\n","        state = new_state\n","        \n","env.close()\n","print (\"Score over time: \" +  str(sum(rewards)/total_test_episodes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmgl64XsUeym","executionInfo":{"status":"ok","timestamp":1639795487021,"user_tz":-420,"elapsed":335807,"user":{"displayName":"Phong Tran Tan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEGvhwcz1ieQ2wD7YMKhz0kWxXjSRzNyD_7a8OMw=s64","userId":"02427881234210477844"}},"outputId":"99a7957d-f768-4e62-ab6a-a62926bd20d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Score over time: 0.03\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"8THjUiuSUfDX"},"execution_count":null,"outputs":[]}]}